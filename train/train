#!/usr/bin/env python3

import tensorflow as tf
import tensorflow_hub as hub

from tensorflow.keras import layers
import tensorflow.keras.backend as K

from tensorflow.python.tools import optimize_for_inference_lib

import os
import sys
import json
import csv
import time

__PROD__ = os.environ.get('LOCAL') != 'True'
prefix = '/opt/ml/'

if __name__ =='__main__':
    if __PROD__:
        from environment import create_trainer_environment
        env = create_trainer_environment()
        
        epochs = env.hyperparameters.get('epochs', default=1, object_type=int)
        steps = env.hyperparameters.get('steps', default=0, object_type=int)
        feature_extractor_url = env.hyperparameters.get('module', default="models/mobilenet_v2_100_224-feature_vector-2", object_type=str)
        data_root = env.channel_dirs['train']
        files = os.listdir(data_root)
        for name in files:
            filename = name
            break
        data_root = data_root + '/' + filename
    else:
        epochs = 1
        steps = 0
        feature_extractor_url = "models/mobilenet_v2_100_224-feature_vector-2"
        data_root = tf.keras.utils.get_file(
            'flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',
            untar=True)
    
    output_dir = os.path.join(prefix, 'model')
    print('output_dir: ' + output_dir)

    image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)

    def feature_extractor(x):
        feature_extractor_module = hub.Module(feature_extractor_url)
        return feature_extractor_module(x)

    IMAGE_SIZE = hub.get_expected_image_size(hub.Module(feature_extractor_url))

    image_data = image_generator.flow_from_directory(str(data_root), target_size=IMAGE_SIZE)
    for image_batch,label_batch in image_data:
        print("Image batch shape: ", image_batch.shape)
        print("Label batch shape: ", label_batch.shape)
        break

    features_extractor_layer = layers.Lambda(feature_extractor, input_shape=IMAGE_SIZE+[3], name="lambda_input")
    features_extractor_layer.trainable = False

    model = tf.keras.Sequential([
        features_extractor_layer,
        layers.Dense(image_data.num_classes, activation='softmax', name='softmax_input')
    ])
    model.summary()
    
    print('--- INPUT NODES ---')
    input_nodes = [node.op.name for node in model.inputs]
    print(input_nodes)
    
    print('--- OUTPUT NODES ---')
    output_nodes = [node.op.name for node in model.outputs]
    print(output_nodes)

    init = tf.global_variables_initializer()
    sess = K.get_session()
    sess.run(init)

    model.compile(
        optimizer=tf.train.AdamOptimizer(),
        loss='categorical_crossentropy',
        metrics=['accuracy'])

    class CollectBatchStats(tf.keras.callbacks.Callback):
        def __init__(self):
            self.batch_losses = []
            self.batch_acc = []

        def on_batch_end(self, batch, logs=None):
            self.batch_losses.append(logs['loss'])
            self.batch_acc.append(logs['acc'])

    steps_per_epoch = image_data.samples//image_data.batch_size
    if steps > 0:
        steps_per_epoch = steps

    print('steps/epoch: ' + str(steps_per_epoch))
    print('steps: ' + str(steps_per_epoch * epochs))
    batch_stats = CollectBatchStats()
    model.fit((item for item in image_data), epochs=epochs,
                        steps_per_epoch=steps_per_epoch,
                        callbacks = [batch_stats],
                        validation_split=int(image_data.samples*0.1))

    label_names = sorted(image_data.class_indices.items(), key=lambda pair:pair[1])
    label_names = [key.title() for key, value in label_names]

    label_txt = ''
    for l in label_names:
        label_txt += l + '\n'

    tf_graph = sess.graph

    frozen_graph = tf.compat.v1.graph_util.convert_variables_to_constants(
        sess, tf_graph.as_graph_def(), output_nodes
    )

    output_graph_def = optimize_for_inference_lib.optimize_for_inference(
        frozen_graph,
        input_nodes, # an array of the input node(s)
        output_nodes, # an array of output nodes
        tf.float32.as_datatype_enum)
    
    print('Writing to: ' + output_dir)
    
    tf.train.write_graph(output_graph_def, output_dir, 'model.pb', as_text=False)
    
    # Write labels to export_path
    with open(os.path.join(output_dir, 'labels.csv'), 'w') as file:
        file.write(label_txt)
    file.close()
