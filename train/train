#!/usr/bin/env python3

import tensorflow as tf
import tensorflow_hub as hub

from tensorflow.keras import layers
import tensorflow.keras.backend as K

from tensorflow.python.tools import optimize_for_inference_lib

import os
import sys
import json
import csv
import time
import math

__PROD__ = os.environ.get('LOCAL') != 'True'
prefix = '/opt/ml/'

def main():
    if __PROD__:
        from environment import create_trainer_environment
        env = create_trainer_environment()
        
        epochs = env.hyperparameters.get('epochs', default=1, object_type=int)
        steps = env.hyperparameters.get('steps', default=0, object_type=int)
        feature_extractor_url = os.path.join('models', env.hyperparameters.get('module', default="mobilenet_v2_100_224-feature_vector-2", object_type=str))
        data_root = env.channel_dirs['train']
        files = os.listdir(data_root)
        print(str(files))
        
        for name in files:
            dirname = name
            break
        data_root = data_root + '/' + dirname
        print('dirname: ' + dirname)
        print('data_root: ' + data_root)
    else:
        print("Running locally")
        epochs = 0
        steps = 1
        feature_extractor_url = "models/mobilenet_v2_100_224-feature_vector-2"
        data_root = tf.keras.utils.get_file(
            'flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',
            untar=True)

    output_dir_root = os.path.join(prefix, 'model')
    output_dir = os.path.join(output_dir_root, str(math.ceil(time.time())))
    print('output_dir: ' + output_dir)

    image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)

    def feature_extractor(x):
        feature_extractor_module = hub.Module(feature_extractor_url)
        return feature_extractor_module(x)

    IMAGE_SIZE = hub.get_expected_image_size(hub.Module(feature_extractor_url))

    image_data = image_generator.flow_from_directory(str(data_root), target_size=IMAGE_SIZE)
    for image_batch,label_batch in image_data:
        print("Image batch shape: ", image_batch.shape)
        print("Label batch shape: ", label_batch.shape)
        break

    input_shape = IMAGE_SIZE+[3]

    features_extractor_layer = layers.Lambda(feature_extractor, input_shape=input_shape, name="lambda_input")
    features_extractor_layer.trainable = False

    model = tf.keras.Sequential([
        features_extractor_layer,
        layers.Dense(image_data.num_classes, activation='softmax', name='softmax_input')
    ])
    model.summary()
    
    print('--- INPUT NODES ---')
    input_nodes = [node.op.name for node in model.inputs]
    print(input_nodes)
    
    print('--- OUTPUT NODES ---')
    output_nodes = [node.op.name for node in model.outputs]
    print(output_nodes)

    label_names = sorted(image_data.class_indices.items(), key=lambda pair:pair[1])
    label_names = [key.title() for key, value in label_names]
    
    #labels = tf.Variable(label_names, trainable=False, name='labels')
    #labels = tf.Variable(label_names, tf.string)

    init = tf.global_variables_initializer()
    sess = K.get_session()
    sess.run(init)
    #sess.run(labels)

    model.compile(
        optimizer=tf.train.AdamOptimizer(),
        loss='categorical_crossentropy',
        metrics=['accuracy'])

    class CollectBatchStats(tf.keras.callbacks.Callback):
        def __init__(self):
            self.batch_losses = []
            self.batch_acc = []

        def on_batch_end(self, batch, logs=None):
            self.batch_losses.append(logs['loss'])
            self.batch_acc.append(logs['acc'])

    steps_per_epoch = image_data.samples//image_data.batch_size
    if steps > 0:
        steps_per_epoch = steps

    print('steps/epoch: ' + str(steps_per_epoch))
    print('steps: ' + str(steps_per_epoch * epochs))
    batch_stats = CollectBatchStats()
    model.fit((item for item in image_data), epochs=epochs,
                        steps_per_epoch=steps_per_epoch,
                        callbacks = [batch_stats],
                        validation_split=int(image_data.samples*0.1))

    label_names = sorted(image_data.class_indices.items(), key=lambda pair:pair[1])
    label_names = [key.title() for key, value in label_names]
    
    label_txt = ''
    for l in label_names:
        label_txt += l + '\n'

    tf_graph = sess.graph

    frozen_graph = tf.graph_util.convert_variables_to_constants(
        sess, tf_graph.as_graph_def(), output_nodes
    )

    output_graph_def = optimize_for_inference_lib.optimize_for_inference(
        frozen_graph,
        input_nodes, # an array of the input node(s)
        output_nodes, # an array of output nodes
        tf.float32.as_datatype_enum)
    
    # Frozen 
    tf.train.write_graph(output_graph_def, output_dir, 'frozen.pb', as_text=False)

    # TFLite for mobile
    # write_tf_lite_sess(sess, output_dir, model.input, model.output)
    
    # Browser model
    convert_to_js(output_nodes)

    # SavedModel for serving
    kdir = tf.contrib.saved_model.save_keras_model(model, output_dir)

    # Write labels to export_path
    with open(os.path.join(output_dir, 'labels.csv'), 'w') as file:
        file.write(label_txt)
    file.close()

def write_tf_lite(path, input, output, input_shape):
    converter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(os.path.join(path, 'saved_model.pb'), input, output, {input[0]: input_shape})

    tflite_model = converter.convert()
    open(os.path.join(path, "mobile.tflite"), "wb").write(tflite_model)

def write_tf_lite_sess(sess, path, input, output):
    converter = tf.contrib.lite.TFLiteConverter.from_session(sess, [input], [output])
    
    tflite_model = converter.convert()
    open(os.path.join(path, "mobile.tflite"), "wb").write(tflite_model)

def convert_to_js(output_node_names):
    print(output_node_names)
    os.system('tensorflowjs_converter \
        --input_format=tf_frozen_model \
        --output_node_names=' + output_node_names[0] + 'frozen.pb web_model')

if __name__ =='__main__':
    main()
